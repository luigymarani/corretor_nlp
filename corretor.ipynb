{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6507a59",
   "metadata": {},
   "source": [
    "# Entendendo o problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8718d",
   "metadata": {},
   "source": [
    "Desenvolver um corretor ortográfico que receba como input uma palavra digitada incorretamente e retorne uma sugestão da palavra corrigida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f4aa78",
   "metadata": {},
   "source": [
    "Exemplo: in: lgica; out: lógica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83b23c",
   "metadata": {},
   "source": [
    "# Lendo o arquivo .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924996e3",
   "metadata": {},
   "source": [
    "Arquivo 'artigos.txt' que contém apenas palavras em português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47508db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o\n"
     ]
    }
   ],
   "source": [
    "# lendo o arquivo .txt:\n",
    "with open(\"artigos.txt\", 'r', encoding='utf8') as f:\n",
    "    artigos = f.read()  # armazena o conteúdo do arquivo nessa variável\n",
    "print(artigos[:200])  # exibe os primeiros 200 caracteres da variável"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654f515",
   "metadata": {},
   "source": [
    "# Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff407f73",
   "metadata": {},
   "source": [
    "Tokenizar, em NLP, se refere a dividir a variável inteira ('artigos') em trechos menores (com o método split(), por exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01454b66",
   "metadata": {},
   "source": [
    "Processo muito utilizado no pré-processamento de dados textuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa70519",
   "metadata": {},
   "source": [
    "## Descobrindo quantas palavras a variável tem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1efe0",
   "metadata": {},
   "source": [
    "### Mostrando o tamanho da variável (número de caracteres, e não de palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4d3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A variável artigos possui 2605046 caracteres.\n"
     ]
    }
   ],
   "source": [
    "print(f'A variável artigos possui {len(artigos)} caracteres.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a876d25",
   "metadata": {},
   "source": [
    "Problemas detectados: existem caracteres de pontuação no meio. Existem palavras com caracteres em caixa alta. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7798ad",
   "metadata": {},
   "source": [
    "## Tokenizando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c2fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  # importando o pacote\n",
    "# nltk.download('punkt')  # fazendo download de outro dado necessário do nltk (senão dá erro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b79210",
   "metadata": {},
   "source": [
    "### Exemplo teste do nltk.tokenize.word_tokenize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648fa7e6",
   "metadata": {},
   "source": [
    "#### Tokenizando o exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a306f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_exemplo = \"Olá, tudo bem?\"  # string exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d66026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá', ',', 'tudo', 'bem', '?']\n"
     ]
    }
   ],
   "source": [
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)  # lista com os tokens\n",
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a68e0",
   "metadata": {},
   "source": [
    "Separou a string em palavras e pontuações, retornando uma lista com todas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298df85c",
   "metadata": {},
   "source": [
    "#### Removendo o que não é palavra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c1682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():  # se não houver pontuação/caractere alfaanumérico...\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e67572",
   "metadata": {},
   "source": [
    "A função acima retorna apenas as palavras de determinada lista, removendo caracteres de pontuação ou numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25a5294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3f21a",
   "metadata": {},
   "source": [
    "### Voltando e gerando a lista de palavras (sem pontuação)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4842fb61",
   "metadata": {},
   "source": [
    "Aplicando a mesma lógica demonstrada no exemplo acima à variável 'artigos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584e0ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403104"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)  # cria a lista de tokens\n",
    "lista_palavras = separa_palavras(lista_tokens)  # retorna a lista apenas com palavras\n",
    "len(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b5a542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A variável artigos possui 403104 palavras\n"
     ]
    }
   ],
   "source": [
    "print(f'A variável artigos possui {len(lista_palavras)} palavras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6df33bb",
   "metadata": {},
   "source": [
    "Problema: Existem palavras sem normalização (maiúscula/minúscula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e16de8",
   "metadata": {},
   "source": [
    "### Normalizando: removendo maiúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51a1caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para deixar todos os caracteres em letras minúsculas\n",
    "def normalização(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:        \n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dbbe0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "# chamando a função \n",
    "lista_normalizada = normalização(lista_palavras)\n",
    "print(lista_normalizada[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d098c2",
   "metadata": {},
   "source": [
    "Problema: existem palavras repetidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0cb2cb",
   "metadata": {},
   "source": [
    "### Removendo palavras duplicadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5be012f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_unique = set(lista_normalizada)\n",
    "len(lista_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b51c1",
   "metadata": {},
   "source": [
    "# Construindo o corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d13623d",
   "metadata": {},
   "source": [
    "## Corretor:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b70497",
   "metadata": {},
   "source": [
    "### Função do corretor que implementa os métodos de correção:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce53a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gera várias palavras novas adicionando letras:\n",
    "def gerar_palavras(palavra):    \n",
    "    fatias = []\n",
    "    for c in range(len(palavra) + 1):        \n",
    "        fatias.append((palavra[:c], palavra[c:]))        \n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deleta_letras(fatias)  # concatena as duas operações (deletar e inserir)\n",
    "    palavras_geradas += troca_letras(fatias)  # concatena de novo\n",
    "    palavras_geradas += inverte_letras(fatias)  # concatena de novo\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb93b7",
   "metadata": {},
   "source": [
    "### Calculando a probabilidade de cada palavra no corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bafabb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras = len(lista_normalizada)  # total de palavras no corpus\n",
    "freq = nltk.FreqDist(lista_normalizada)  # calcula a frequência (número de vezes) que cada palavra aparece no corpus\n",
    "\n",
    "\n",
    "# calcula a probabilidade que CADA PALAVRA aparece no corpus de amostra\n",
    "def probabilidade(palavra_gerada): \n",
    "    return freq[palavra_gerada]/total_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58388f2",
   "metadata": {},
   "source": [
    "### Corretor em si:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d84858e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerar_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c975e3a8",
   "metadata": {},
   "source": [
    "## Métodos de correção:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb22b4",
   "metadata": {},
   "source": [
    "### Método de correção 1: inserir letra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e951da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):  \n",
    "    novas_palavras = []    \n",
    "    for l, r in fatias:  # left & right\n",
    "        for letra in 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç':\n",
    "            novas_palavras.append(l + letra + r)\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d23f42d",
   "metadata": {},
   "source": [
    "### Método de correção 2: remover letra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca3ce9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleta_letras(fatias):\n",
    "    novas_palavras = []    \n",
    "    for l, r in fatias:  # left & right\n",
    "        novas_palavras.append(l + r[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59253c33",
   "metadata": {},
   "source": [
    "### Método de correção 3: trocar letra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307205e2",
   "metadata": {},
   "source": [
    "Para quando escrever uma letra errada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62d23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def troca_letras(fatias):  \n",
    "    novas_palavras = []    \n",
    "    for l, r in fatias:  # left & right        \n",
    "        for letra in 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç':\n",
    "            novas_palavras.append(l + letra + r[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488985d4",
   "metadata": {},
   "source": [
    "### Método de correção 4: inverte letra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd544347",
   "metadata": {},
   "source": [
    "Para quando inverter as letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10884858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverte_letras(fatias):\n",
    "    novas_palavras = []      \n",
    "    for l, r in fatias:  # left & right\n",
    "        if len(r) > 1:\n",
    "            novas_palavras.append(l + r[1] + r[0] + r[2:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fb0af",
   "metadata": {},
   "source": [
    "### Avaliando o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d531ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que extrai palavras teste do arquivo 'palavras.txt'\n",
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\", encoding='utf-8')\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9008812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_teste = cria_dados_teste('palavras.txt')  # lista com palavras teste do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfe71043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contruindo função para avaliar a taxa de acerto do corretor\n",
    "def avaliador(testes):\n",
    "    num_palavras = len(testes)\n",
    "    acertos = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertos += 1\n",
    "    taxa_acerto = acertos/num_palavras*100\n",
    "    print(f'Taxa de acerto: acertou {taxa_acerto:.2f}% de um total de {num_palavras} palavras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88128e36",
   "metadata": {},
   "source": [
    "#### Testando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84844abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: acertou 76.34% de um total de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d30ae4e",
   "metadata": {},
   "source": [
    "# Testando a taxa de palavras desconhecidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d265fc0",
   "metadata": {},
   "source": [
    "Função avaliador() atualizada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37ed10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador_2(testes, vocab):\n",
    "    num_palavras = len(testes)\n",
    "    acertos = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertos += 1\n",
    "        elif correta not in vocab:            \n",
    "            desconhecida += 1\n",
    "    taxa_acerto = acertos/num_palavras*100\n",
    "    taxa_desconhecida = desconhecida/num_palavras*100\n",
    "    print(f'Taxa de acerto: acertou {taxa_acerto:.2f}% de um total de {num_palavras} palavras')\n",
    "    print(f'Taxa de palavras desconhecidas: {taxa_desconhecida:.2f}%')\n",
    "\n",
    "vocab = set(lista_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e7b9e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: acertou 76.34% de um total de 186 palavras\n",
      "Taxa de palavras desconhecidas: 6.99%\n"
     ]
    }
   ],
   "source": [
    "avaliador_2(lista_teste, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a037610",
   "metadata": {},
   "source": [
    "# Criando um corretor \"turbinado\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea7333",
   "metadata": {},
   "source": [
    "## Função gerador_turbinado() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0296d3",
   "metadata": {},
   "source": [
    "Antes corrigia apenas um erro por vez. Agora vai corrigir até dois erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01e73229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# novo gerador, que recebe uma lista de palavras geradas e, para cada uma delas, gera novas palavras de novo \n",
    "def gerador_turbinado(palavras_geradas):  \n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:  # chama o método gerar_palavras() para cada palavra gerada\n",
    "        novas_palavras += gerar_palavras(palavra)\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcddd722",
   "metadata": {},
   "source": [
    "### Testando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23efefc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_g = gerador_turbinado(gerar_palavras('lóiigica'))\n",
    "'lógica' in palavras_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6c95d",
   "metadata": {},
   "source": [
    "#### Verificando o tamanho -> quantidade de palavras geradas pelo gerador_turbinado()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0fb3fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691744\n"
     ]
    }
   ],
   "source": [
    "print(len(palavras_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c77bb",
   "metadata": {},
   "source": [
    "## Função novo_corretor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff3f20",
   "metadata": {},
   "source": [
    "Diminuindo os candidatos à palavra correta, descartando os menos prováveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84d03f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerar_palavras(palavra)  # lista com palavras geradas pelo método gerar_palavras()\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)  # lista com palavras geradas pelo método gerar_turbinado()\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)  # concatena as duas listas acima\n",
    "    candidatos = [palavra]  # a priori essa var contém apenas a palavra inicial (caso esteja correta, e não errada)\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocab:\n",
    "            candidatos.append(palavra)\n",
    "    palavra_correta = max(candidatos, key=probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312341f0",
   "metadata": {},
   "source": [
    "### Testando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9e291a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novo_corretor('lóiigica')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750753f",
   "metadata": {},
   "source": [
    "## Novo avaliador()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ff970",
   "metadata": {},
   "source": [
    "Corrigindo erros do avaliador prévio e aplicando o novo_corretor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "763b0231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: acertou 55.38% de um total de 186 palavras\n",
      "Taxa de palavras desconhecidas: 6.99%\n"
     ]
    }
   ],
   "source": [
    "def avaliador_3(testes, vocab):\n",
    "    num_palavras = len(testes)\n",
    "    acertos = desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = novo_corretor(errada)  # novo corretor\n",
    "        desconhecida += (correta not in vocab)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertos += 1\n",
    "    taxa_acerto = acertos/num_palavras*100\n",
    "    taxa_desconhecida = desconhecida/num_palavras*100\n",
    "    print(f'Taxa de acerto: acertou {taxa_acerto:.2f}% de um total de {num_palavras} palavras')\n",
    "    print(f'Taxa de palavras desconhecidas: {taxa_desconhecida:.2f}%')\n",
    "\n",
    "vocab = set(lista_normalizada)\n",
    "avaliador_3(lista_teste, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ccfee",
   "metadata": {},
   "source": [
    "# Função avaliadora final: avaliador_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec6679",
   "metadata": {},
   "source": [
    "Após comparação, o novo_corretor() possui, na verdade, pior performance que o corretor()\n",
    "- Por isso, a versão final do avaliador vai usar o corretor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dde7b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto: acertou 76.34% de um total de 186 palavras\n",
      "Taxa de palavras desconhecidas: 6.99%\n"
     ]
    }
   ],
   "source": [
    "def avaliador_4(testes, vocab):\n",
    "    num_palavras = len(testes)\n",
    "    acertos = desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)  # usando o corretor original \n",
    "        desconhecida += (correta not in vocab)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertos += 1\n",
    "    taxa_acerto = acertos/num_palavras*100\n",
    "    taxa_desconhecida = desconhecida/num_palavras*100\n",
    "    print(f'Taxa de acerto: acertou {taxa_acerto:.2f}% de um total de {num_palavras} palavras')\n",
    "    print(f'Taxa de palavras desconhecidas: {taxa_desconhecida:.2f}%')\n",
    "\n",
    "vocab = set(lista_normalizada)\n",
    "avaliador_4(lista_teste, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b83a4e",
   "metadata": {},
   "source": [
    "## Comparando resultados entre as duas versões dos corretores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8548b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novo_corretor(): lógica\n",
      "corretor(): aloogica\n"
     ]
    }
   ],
   "source": [
    "palavra = 'loogica'  # inserir a palavra teste aqui\n",
    "print(f'novo_corretor(): {novo_corretor(palavra)}')\n",
    "print(f'corretor(): {corretor(palavra)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
